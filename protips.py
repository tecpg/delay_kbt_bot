from cmath import cos
from csv import DictReader, writer
import csv
import datetime
from lib2to3.pgen2 import driver
import pprint
from pydoc import stripid
import random
import string
import sys
import traceback
from unittest import result
from urllib import request
import requests
from bs4 import BeautifulSoup as soup
import time
from wsgiref import headers
# importing webdriver from selenium
import requests
import os
import time
import io
import requests
import mysql.connector
from mysql.connector import errorcode

from lxml import etree
from datetime import datetime
from datetime import timedelta
from datetime import date
from wp_post_api_bot import wp_post
import kbt_load_env
from consts import global_consts as gc
import kbt_funtions



global csv_data
csv_f = gc.PROTIPS_CSV

session = requests.Session()
my_headers = gc.MY_HEARDER
dt = []

# taking input as the current date
# today() method is supported by date
# class in datetime module

p_date = gc.PRESENT_DAY_DATE
# calculating end date by adding 4 days
x_date = gc.YESTERDAY_DATE

# # printing end date
# print("Ending date")
print(x_date)


def get_today_prediction(bs, set_date):

    url ="https://www.betensured.com/?date="
   
    webpage = requests.get(url+str(set_date)+"&sport=1", headers = my_headers)
    bs = bs(webpage.content, "html.parser")
    dom = etree.HTML(str(bs))

    #get table row count for the tr loop

    tables = bs.find("div", {"id": "pills-football-tabContent"})
    table = tables.findChildren('table')
    web_table = table[0]
    rows = web_table.findChildren(['tr'])
    tr_count = len(rows)
    print("Table has ",tr_count - 1," rows")

    #open csv file

    try:
            with open(csv_f, "w", encoding="utf8", newline="") as f:
                thewriter = writer(f)
                protip = ''

                for x in range(0, tr_count - 4):
                    c = 1 + x
                    i = str(c)
                    if c > 1:
                        protip = 'yes'
                    else:
                        protip = 'No'
                    try:
                        league = dom.xpath(f'//*[@id="pills-football"]/div[2]/table/tbody/tr[{i}]/td[1]/div/div[1]/small')
                        leagues = league[0].text

                        # Try the primary XPath expression for fixtures
                        try:
                            fixtures = dom.xpath(f'//*[@id="pills-football"]/div[2]/table/tbody/tr[{i}]/td[1]/div/div[2]/a/div/span')
                            fixtures = fixtures[0].text 
                            
                            
                        except IndexError:
                            # Use an alternate XPath expression or set a default value
                            noLink_fixtures = dom.xpath(f'//*[@id="pills-football"]/div[2]/table/tbody/tr[{i}]/td[1]/div/div[2]/div/span')
                            fixtures = noLink_fixtures[0].text if noLink_fixtures else "N/A"

                        picks = dom.xpath(f'//*[@id="pills-football"]/div[2]/table/tbody/tr[{i}]/td[3]/span/b')
                        picks = picks[0].text
                   
                        results = "N/A"
                        timez = "--:--"
                        odds = "N/A"
                        source = "protips_acca"
                        flag = ""
                        match_date = set_date
                        match_code = kbt_funtions.get_code(8)
                        score = ""
                        
                    except IndexError:
                        print(f"Error: IndexError occurred at index {i}")
                        traceback.print_exc()  # This will print the traceback for debugging purposes
                        continue  # Skip this iteration and proceed with the next one

                    prediction = [leagues, fixtures, picks, odds, timez, score, match_date, flag, results, match_code, source, protip]
                    dt.append(prediction)

                thewriter.writerows(dt)

            print(dt)
            print(fixtures)
    except Exception as e:
        print("An error occurred:", e)
        traceback.print_exc()

        

def get_previous_prediction(nbs,set_previous_date):

    url ="https://www.betensured.com/?date="
   
    webpage = requests.get(url+str(set_previous_date)+"&sport=1", headers = my_headers)
    nbs = nbs(webpage.content, "html.parser")
    dom = etree.HTML(str(nbs))

    #get table row count for the tr loop
    tables = nbs.find("div", {"id": "pills-football-tabContent"})
    table = tables.findChildren('table')
    web_table = table[0]
    rows = web_table.findChildren(['tr'])
    tr_count = len(rows)
    print("Table has ",tr_count - 1," rows")

    #open csv file

  

    try:
        with open(csv_f, "w", encoding="utf8", newline="") as f:
            thewriter = writer(f)
            for x in range(0, tr_count - 4):
                c = 1 + x
                i = str(c)

                timez = "N/A"
                try:
                    league = dom.xpath(f'//*[@id="pills-football"]/div[2]/table/tbody/tr[{i}]/td[1]/div/div[1]/small')
                    leagues = league[0].text


                                 # Try the primary XPath expression for fixtures
                    try:
                        fixtures = dom.xpath(f'//*[@id="pills-football"]/div[2]/table/tbody/tr[{i}]/td[1]/div/div[2]/a/div/span')
                        fixtures = fixtures[0].text
                    except IndexError:
                        # Use an alternate XPath expression or set a default value
                        noLink_fixtures = dom.xpath(f'//*[@id="pills-football"]/div[2]/table/tbody/tr[{i}]/td[1]/div/div[2]/div/span')
                        fixtures = noLink_fixtures[0].text if noLink_fixtures else "N/A"
                        

                    picks = dom.xpath(f'//*[@id="pills-football"]/div[2]/table/tbody/tr[{i}]/td[3]/span/b')
                    picks = picks[0].text
                    score = dom.xpath(f'//*[@id="pills-football"]/div[2]/table/tbody/tr[{i}]/td[4]/span')
                    score = score[0].text
                    results = dom.xpath(f'//*[@id="pills-football"]/div[2]/table/tbody/tr[{i}]/td[5]/span/@class')
                                      
                    res = results
                except IndexError:
                    print(f"Error: IndexError occurred at index {i}")
                    traceback.print_exc()  # This will print the traceback for debugging purposes
                    continue  # Skip this iteration and proceed with the next one

                if 'fa fa-check-circle text-success' in res and score != '?':
                    results = "Won"
                elif 'fa fa-times-circle text-danger' in res and score != '?':
                    results = "Lost"
                elif score == '?':
                    results = "..."

                odds = "N/A"
                source = "protips_acca"
                flag = ""
                match_date = set_previous_date
                match_code = kbt_funtions.get_code(8)
                protip = 'No'

                prediction = [leagues, fixtures,  picks, odds, timez, score, match_date, flag, results, match_code, source, protip]
                dt.append(prediction)

            thewriter.writerows(dt)
            print(dt)

    except Exception as e:
        print("An error occurred:", e)
        traceback.print_exc()
        


#csv_f = "venasbet_data.csv"
def connect_server():
    #NOTE::::::::::::when i experience bad connection: 10458 (28000) in ip i browse my ip address and paste it inside cpanel add host then copy my cpanel sharedhost ip
    #and paste here as my host ip address
    try:
        connection = kbt_funtions.db_connection()
        
        if connection.is_connected():
            db_Info = connection.get_server_info()
            print("Connected to MySQL Server version ", db_Info)
            cursor = connection.cursor()
            cursor.execute("select database();")
            record = cursor.fetchone()

            print("You're connected to database: ", record)

        
            
        with open(csv_f, "r") as f:
        
            csv_data = csv.reader(f)
            for row in csv_data:
                print(row)
                cursor.execute('INSERT INTO soccerpunt(league,fixtures,tip,odd,match_time,score,date,flag,result,code,source,protip)'\
                    'VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)', row)

        print("Inserting tips now... ", time.ctime())
        print(cursor.rowcount," record(s) created==============", time.ctime())

        
        time.sleep(6) 
        print("==============Bot is taking a nap... whopps!==================== ", time.ctime())  
        print("============Bot deleting previous tips from  database:=============== ")


        cursor.execute('DELETE t1 FROM soccerpunt AS t1 INNER JOIN soccerpunt AS t2 WHERE t1.id < t2.id AND t1.fixtures = t2.fixtures AND t1.source = t2.source')

            
        print(cursor.rowcount," record(s) deleted==============", time.ctime()) 

    

    except mysql.connector.Error as err:
        if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:
            print("Something is wrong with your user name or password ", err)
        elif err.errno == errorcode.ER_BAD_DB_ERROR:
            print("Database does not exist")
        else:
            print("Error while connecting to MySQL", err)

    finally:
        if connection and connection.is_connected():
            cursor.close()
            connection.commit()
            connection.close()
                
            print("MySQL connection is closed")


def run():
    get_today_prediction(soup,p_date)
    #time.sleep(6) 
    #print("==============Bot is taking a nap... whopps!==================== ", time.ctime())  
    get_previous_prediction(soup,x_date)
    #print(get_result("2X","2:2"))
    # #insert into db
    connect_server()
   


if __name__ == "__main__":
    run()

    
